{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "terminal-hopkins",
   "metadata": {},
   "source": [
    "### import modules for numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exempt-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "technological-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "wines = np.genfromtxt(\"winequality-red.csv\",delimiter=\";\",skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-expansion",
   "metadata": {},
   "source": [
    "### What is its size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "virgin-gibson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-greece",
   "metadata": {},
   "source": [
    "### How many wine data rows here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sticky-provision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-polyester",
   "metadata": {},
   "source": [
    "### How many wine data columns here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surface-appearance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-punch",
   "metadata": {},
   "source": [
    "### How many dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "applicable-repository",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-associate",
   "metadata": {},
   "source": [
    "### What is the type of wines?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "transparent-employer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-polls",
   "metadata": {},
   "source": [
    "### What is the data type of wines data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mexican-timber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-westminster",
   "metadata": {},
   "source": [
    "### Show top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wireless-objective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.400e+00, 7.000e-01, 0.000e+00, 1.900e+00, 7.600e-02, 1.100e+01,\n",
       "        3.400e+01, 9.978e-01, 3.510e+00, 5.600e-01, 9.400e+00,       nan],\n",
       "       [7.800e+00, 8.800e-01, 0.000e+00, 2.600e+00, 9.800e-02, 2.500e+01,\n",
       "        6.700e+01, 9.968e-01, 3.200e+00, 6.800e-01, 9.800e+00,       nan],\n",
       "       [7.800e+00, 7.600e-01, 4.000e-02, 2.300e+00, 9.200e-02, 1.500e+01,\n",
       "        5.400e+01, 9.970e-01, 3.260e+00, 6.500e-01, 9.800e+00,       nan],\n",
       "       [1.120e+01, 2.800e-01, 5.600e-01, 1.900e+00, 7.500e-02, 1.700e+01,\n",
       "        6.000e+01, 9.980e-01, 3.160e+00, 5.800e-01, 9.800e+00,       nan],\n",
       "       [7.400e+00, 7.000e-01, 0.000e+00, 1.900e+00, 7.600e-02, 1.100e+01,\n",
       "        3.400e+01, 9.978e-01, 3.510e+00, 5.600e-01, 9.400e+00,       nan]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-hungarian",
   "metadata": {},
   "source": [
    "### What is the value at 3rd row, 4th column of wine data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pleasant-delaware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-floor",
   "metadata": {},
   "source": [
    "### Select first 3 items in 4th column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "opponent-demonstration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9, 2.6, 2.3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:3,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-publication",
   "metadata": {},
   "source": [
    "### Show 1st column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "studied-march",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.4, 7.8, 7.8, ..., 6.3, 5.9, 6. ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-donor",
   "metadata": {},
   "source": [
    "### Show 2nd row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reserved-showcase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.8   ,  0.88  ,  0.    ,  2.6   ,  0.098 , 25.    , 67.    ,\n",
       "        0.9968,  3.2   ,  0.68  ,  9.8   ,     nan])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-attraction",
   "metadata": {},
   "source": [
    "### Select items from rows 1 to 3 and 5th column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "difficult-pasta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.098, 0.092, 0.075])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[1:4,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-alarm",
   "metadata": {},
   "source": [
    "### Change 1st value in wines to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "seasonal-norfolk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "affected-trance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[0,0]=100\n",
    "wines[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-webmaster",
   "metadata": {},
   "source": [
    "###  change it back to 7.4 and print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "indirect-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "wines[0,0]=7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-university",
   "metadata": {},
   "source": [
    "## 1-Dimensional Numpy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-reading",
   "metadata": {},
   "source": [
    "### Select 4th row all column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "listed-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = wines[3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-kernel",
   "metadata": {},
   "source": [
    "### display its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "normal-tension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.2  ,  0.28 ,  0.56 ,  1.9  ,  0.075, 17.   , 60.   ,  0.998,\n",
       "        3.16 ,  0.58 ,  9.8  ,    nan])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-tennis",
   "metadata": {},
   "source": [
    "### show 2nd value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hawaiian-allowance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-discretion",
   "metadata": {},
   "source": [
    "### Convert wine data to integer values and show it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unusual-popularity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[          7,           0,           0, ...,           0,\n",
       "                  9, -2147483648],\n",
       "       [          7,           0,           0, ...,           0,\n",
       "                  9, -2147483648],\n",
       "       [          7,           0,           0, ...,           0,\n",
       "                  9, -2147483648],\n",
       "       ...,\n",
       "       [          6,           0,           0, ...,           0,\n",
       "                 11, -2147483648],\n",
       "       [          5,           0,           0, ...,           0,\n",
       "                 10, -2147483648],\n",
       "       [          6,           0,           0, ...,           0,\n",
       "                 11, -2147483648]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-singles",
   "metadata": {},
   "source": [
    "## Vectorization Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-excerpt",
   "metadata": {},
   "source": [
    "### Increase wine quality score (output variable) by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "solid-spring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:,11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-syndicate",
   "metadata": {},
   "source": [
    "### Increase by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "retained-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "wines[:,11]+=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-bride",
   "metadata": {},
   "source": [
    "### Display update score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "academic-october",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:,11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-hawaiian",
   "metadata": {},
   "source": [
    "### Multiply alcohol of all wine data by 3 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "liberal-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "wines[:,10]*=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-track",
   "metadata": {},
   "source": [
    "### Show updated alcohol column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "finished-novel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.2, 29.4, 29.4, ..., 33. , 30.6, 33. ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-appraisal",
   "metadata": {},
   "source": [
    "### Add quality column by itselt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "clean-casino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:,11]+wines[:,11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-lingerie",
   "metadata": {},
   "source": [
    "### Multiply alcohol and wine quality columns. It will perform element wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "metric-operations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:,11]*wines[:,11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-trustee",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-integral",
   "metadata": {},
   "source": [
    "### Add every row of wines data with a random array of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "excessive-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_array= np.random.rand(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-horror",
   "metadata": {},
   "source": [
    "### Show rand_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cognitive-shadow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02040216, 0.26064878, 0.91209823, 0.49145081, 0.01888664,\n",
       "       0.12347569, 0.22467662, 0.60465184, 0.61851249, 0.20670601,\n",
       "       0.83757304, 0.3259706 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-analysis",
   "metadata": {},
   "source": [
    "### add wines and rand_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "married-charlotte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.42040216,  0.96064878,  0.91209823, ...,  0.76670601,\n",
       "        29.03757304,         nan],\n",
       "       [ 7.82040216,  1.14064878,  0.91209823, ...,  0.88670601,\n",
       "        30.23757304,         nan],\n",
       "       [ 7.82040216,  1.02064878,  0.95209823, ...,  0.85670601,\n",
       "        30.23757304,         nan],\n",
       "       ...,\n",
       "       [ 6.32040216,  0.77064878,  1.04209823, ...,  0.95670601,\n",
       "        33.83757304,         nan],\n",
       "       [ 5.92040216,  0.90564878,  1.03209823, ...,  0.91670601,\n",
       "        31.43757304,         nan],\n",
       "       [ 6.02040216,  0.57064878,  1.38209823, ...,  0.86670601,\n",
       "        33.83757304,         nan]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines+rand_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
